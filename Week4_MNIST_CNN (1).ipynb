{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVz6YR07MY1V"
      },
      "source": [
        "# Practical Machine Learning for Physicists\n",
        "## Week 4 Exercise - Part 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqw6IpHeMY1W"
      },
      "source": [
        "### Task 1:\n",
        "Design, implement and test a neural network utilising a single convolutional layer (use as many other non convolutional layers as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using a single convolutional layer?\n",
        "\n",
        "### Task 2:\n",
        "Design, implement and test a neural network utitlising multiple convolutional layers (again use as many other non convolutinal laters as you need) to classify the MNIST handwritten digits. What is the maximum test accuracry you can achieve using as many convolutional layers as you like?\n",
        "\n",
        "#### Practicalities\n",
        "You should use this notebook for your work and upload it to both Moodle and CoCalc. You are expected to use TensorFlow and Keras to complete these takss. The notebook should be self-contained and able to be executed if necessary. Marks will be awarded for (roughly equally weighted):\n",
        "- Overall notebook clarity (both in terms of good coding practice and coherent discussion)\n",
        "- Network performance (how well does your classifier do?)\n",
        "- Network efficiency (how does your network compare to the optimum networks for this task?)\n",
        "- Network training (do you do a good job of traning your network?)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________________________________________"
      ],
      "metadata": {
        "id": "_fyONoK-fXmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import what's needed and set-up figure display conditions."
      ],
      "metadata": {
        "id": "5XjOZheCfNyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlHBZCeLMY1X",
        "outputId": "9b6a8ac6-4818-47e0-a9e5-f9fea0dcfac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.style #Some style nonsense\n",
        "import matplotlib as mpl #Some more style nonsense\n",
        "\n",
        "\n",
        "#Set default figure size\n",
        "#mpl.rcParams['figure.figsize'] = [12.0, 8.0] #Inches... of course it is inches\n",
        "mpl.rcParams[\"legend.frameon\"] = False\n",
        "mpl.rcParams['figure.dpi']=200 # dots per inch\n",
        "\n",
        "#Useful for debugging problems\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and store the MNIST dataset, also rescaling it to mormalize the values."
      ],
      "metadata": {
        "id": "zoQsj5n-fbjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist   #The original handwritten digit MNIST\n",
        "#f_mnist = keras.datasets.fashion_mnist   #A tricky version that uses images of fashion items\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Rescaling both image sets so that values are relative to 1\n",
        "train_images=train_images/255.0\n",
        "test_images=test_images/255.0"
      ],
      "metadata": {
        "id": "vkjFu5O7M0Im"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[570])  # Displays an image from the dataset.\n",
        "plt.colorbar()                 #Generates a colorbar for the image, telling us what values the colours represent."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "u0Aot2qmXRLj",
        "outputId": "16242923-cf50-4a60-c677-5eb113cace98"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f584654abb0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: A Single Convolutional Layer\n",
        "Let's now try to setup a model with hidden layers, including a single convolutional layer."
      ],
      "metadata": {
        "id": "9gqr3Na8iIAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()                                                      #load a keras-model in 'model'\n",
        "model.add(keras.layers.Conv2D(5, (3,3), activation='relu', input_shape=(28, 28, 1)))   #Add a convolution layer which takes an input of a single colour 28x28 image. Twenty eight of 3x3 kernels are applied to the image.\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))                                           #Add a pooling layer (2x2 dimensions) that downsamples from 28x28 to 14x14. Maxpooling selects the brighter spots in the image.\n",
        "\n",
        "model.summary()                                                                        #Generate a summary of the parameters and output shapes of the layers in the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV1GqUDpN8dX",
        "outputId": "fb951380-9551-4939-b6da-44b4f5c6854f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 5)         50        \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 13, 13, 5)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50\n",
            "Trainable params: 50\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...adding some hidden fully-connected layers."
      ],
      "metadata": {
        "id": "FDfNDbQnrosz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(keras.layers.Flatten(input_shape=(28,28)))                                     #Adding a flattening layer that converts the 28x28 image into a string of 784x1.\n",
        "model.add(keras.layers.Dense(128, activation='relu'))                                    #Adding a fully connected hidden layer with 128 neurons and relu activation.\n",
        "model.add(keras.layers.Dense(10))                                                        #Adding an output layer that seperates the dataset into 10 classes of objects (corresponding to the 10 digits).\n",
        "\n",
        "model.summary()                                                                          #Generate a summary of the parameters and output shapes of the layers in the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcD2PEddWML1",
        "outputId": "88df6500-9abe-465d-9970-f29b0f6c6e5e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 26, 26, 5)         50        \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 13, 13, 5)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 845)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               108288    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,628\n",
            "Trainable params: 109,628\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',                                                         # Compile the model with 'adam' optimizer'\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),     # Added in code to output the loss and accuracy values when asked for it.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5,                              # Teach the model via the training images and labels provided, repeating this for 5 epochs (rounds of teaching and testing).\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UKlQG4CWhtw",
        "outputId": "1a2a234e-0718-4720-99a4-304d7fe246b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.2253 - accuracy: 0.9341 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0764 - accuracy: 0.9770 - val_loss: 0.0649 - val_accuracy: 0.9796\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.0556 - val_accuracy: 0.9831\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.0450 - val_accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0261 - accuracy: 0.9918 - val_loss: 0.0480 - val_accuracy: 0.9843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I used 5 epochs as it netted a pretty good accuracy level while also not making the code long to run.**"
      ],
      "metadata": {
        "id": "ADmC_Yu-3IYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(test_images))                                                            # Print the shape of the 'test_images' data set. Out outs as (number of images, x-pixels, y-pixels)\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)              # Store and print the final accuracy and loss values for test.\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yzHQQe8WzAR",
        "outputId": "ffd23b61-e0ad-45d1-d0b0-efc9890b2f69"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "313/313 - 2s - loss: 0.0480 - accuracy: 0.9843 - 2s/epoch - 6ms/step\n",
            "\n",
            "Test accuracy: 0.9843000173568726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this task, I maximized the accuracy by varying the number of neurons in the hidden layer, the number of kernels applied to the image in the convolution layer and the size of the kernels in the convolution layer. Although I originally used 28 kernels in the conv layer, I later reduced it to 5 after seeing minimal differences in accuracy while seeing a marked improvement in time taken to run the code. In the interest of maintaining a reasonably complex NN, I kept the kernel size to 3x3 instead of increasing it.**"
      ],
      "metadata": {
        "id": "2KaHnBPt3boO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________"
      ],
      "metadata": {
        "id": "v5Jmd5CK42tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Multiple Convolutional Layers\n",
        "\n",
        "Let's now try to setup a model with multiple convolutional layers."
      ],
      "metadata": {
        "id": "lcpsEHlU421G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The activation will be kept as 'relu', as it seems to generate sharper guesses as comapred to the 'smoother' guesses of sigmoid, which can be seen by the graphs they symbolize."
      ],
      "metadata": {
        "id": "I8_8-_Bf5x3Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "u21BuEb4yS20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8bd9bab-e236-475b-9d81-dc52b6caf56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 26, 26, 5)         50        \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 5)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 11, 11, 10)        460       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 10)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 3, 3, 10)          910       \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 90)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               11648     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,358\n",
            "Trainable params: 14,358\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.Sequential()                                                                  #load a keras-model in 'model'\n",
        "model.add(keras.layers.Conv2D(5, (3, 3), activation='relu', input_shape=(28, 28, 1)))              #Add a convolution layer which takes an input of a single colour 28x28 image. 5 of 3x3 kernels are applied to the image.\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))                                                       #Add a pooling layer (2x2 dimensions) that downsamples from 28x28 to 14x14.\n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      #Add a convolution layer. 10 of 3x3 kernels are applied to the image.\n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))                                                       #Add a pooling layer (2x2 dimensions) that downsamples from 28x28 to 14x14.\n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      #Add a convolution layer. 10 of 3x3 kernels are applied to the image.\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))                                               #Adding a flattening layer that converts the 28x28 image into a string of 784x1.\n",
        "model.add(keras.layers.Dense(128, activation='relu'))                                              #Adding a fully connected hidden layer with 128 neurons and relu activation.\n",
        "model.add(keras.layers.Dense(10))                                                                  #Adding an output layer that seperates the dataset into 10 classes of objects (corresponding to the 10 digits).\n",
        "\n",
        "model.summary()                                                                                    #Generate a summary of the parameters and output shapes of the layers in the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',                                                                    # Compile the model with 'adam' optimizer'\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),                # Added in code to output the loss and accuracy values when asked for it.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5,                                         # Teach the model via the training images and labels provided, repeating this for 5 epochs (rounds of teaching and testing).\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ9mAvvJhivv",
        "outputId": "ba9a7989-592f-4f7d-ee6b-0b4840c73b3b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.2657 - accuracy: 0.9190 - val_loss: 0.0973 - val_accuracy: 0.9695\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1009 - accuracy: 0.9688 - val_loss: 0.0716 - val_accuracy: 0.9761\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0773 - accuracy: 0.9755 - val_loss: 0.0683 - val_accuracy: 0.9761\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0633 - accuracy: 0.9800 - val_loss: 0.0543 - val_accuracy: 0.9828\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0546 - accuracy: 0.9825 - val_loss: 0.0505 - val_accuracy: 0.9833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(test_images))                                                               # Print the shape of the 'test_images' data set. Out outs as (number of images, x-pixels, y-pixels)\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)                 # Store and print the final accuracy and loss values for test.\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohiBTmlEhttj",
        "outputId": "adc32218-cc89-4bb7-aa4b-dcd245177755"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "313/313 - 2s - loss: 0.0505 - accuracy: 0.9833 - 2s/epoch - 6ms/step\n",
            "\n",
            "Test accuracy: 0.983299970626831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering that there is similar accuracy in the two scenerios, it can be said that increasing convolutions doesn't necessarily increase the accuracy, in fact, the accuracy seems to decrease in our case. **Let's test this out with more convolution layers added.**"
      ],
      "metadata": {
        "id": "b4znEkrPUKZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()                                                                  #load a keras-model in 'model'\n",
        "model.add(keras.layers.Conv2D(5, (3, 3), activation='relu', input_shape=(28, 28, 1)))              #Add a convolution layer which takes an input of a single colour 28x28 image. 5 of 3x3 kernels are applied to the image.\n",
        "\n",
        "#Add 5 convolution layers. 10 of 3x3 kernels are applied to the image in each layer.\n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      \n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      \n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      \n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      \n",
        "model.add(keras.layers.Conv2D(10, (3, 3), activation='relu'))                                      \n",
        "model.add(keras.layers.MaxPooling2D((2, 2)))                                                       #Add a pooling layer (2x2 dimensions) that downsamples from 28x28 to 14x14.\n",
        "\n",
        "\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))                                               #Adding a flattening layer that converts the 28x28 image into a string of 784x1.\n",
        "model.add(keras.layers.Dense(128, activation='relu'))                                              #Adding a fully connected hidden layer with 128 neurons and relu activation.\n",
        "model.add(keras.layers.Dense(10))                                                                  #Adding an output layer that seperates the dataset into 10 classes of objects (corresponding to the 10 digits).\n",
        "\n",
        "model.summary()                                                                                    #Generate a summary of the parameters and output shapes of the layers in the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqNBMDAfUi4w",
        "outputId": "85d61a8d-290a-4e5e-8e08-b08a02f8f0dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (None, 26, 26, 5)         50        \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 24, 24, 10)        460       \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 22, 22, 10)        910       \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 20, 20, 10)        910       \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 18, 18, 10)        910       \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 16, 16, 10)        910       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 10)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 640)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               82048     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,488\n",
            "Trainable params: 87,488\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',                                                                    # Compile the model with 'adam' optimizer'\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),                # Added in code to output the loss and accuracy values when asked for it.\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5,                                         # Teach the model via the training images and labels provided, repeating this for 5 epochs (rounds of teaching and testing).\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlYWqm-ubx_-",
        "outputId": "1482d884-adfe-479d-beeb-c59e8488fb8b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 129s 68ms/step - loss: 0.1599 - accuracy: 0.9507 - val_loss: 0.0577 - val_accuracy: 0.9803\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 121s 65ms/step - loss: 0.0554 - accuracy: 0.9836 - val_loss: 0.0476 - val_accuracy: 0.9835\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 121s 65ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0392 - val_accuracy: 0.9876\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 134s 71ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.0398 - val_accuracy: 0.9874\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 130s 69ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0554 - val_accuracy: 0.9816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(test_images))                                                               # Print the shape of the 'test_images' data set. Out outs as (number of images, x-pixels, y-pixels)\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)                 # Store and print the final accuracy and loss values for test.\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVae6uRncKjj",
        "outputId": "88621952-dcc7-4717-a53d-e6a19899752e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "313/313 - 6s - loss: 0.0554 - accuracy: 0.9816 - 6s/epoch - 19ms/step\n",
            "\n",
            "Test accuracy: 0.9815999865531921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As you can see, adding many more convoluting layers while keeping the other layers the same results in a slight decrease in accuracy, which might be due to convolution leading to loss in data. This indicates that using more convolutions does not increase accuracy necessarily. Also, the processing times for the code also increased substantially due to the increased layers.**"
      ],
      "metadata": {
        "id": "dn6MfrSjfUJs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Bs6PvNCf2FT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}